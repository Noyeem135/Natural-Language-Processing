{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"At a very high level, machine learning is the process of teaching a computer system how to make accurate predictions when fed data.\n",
    "\n",
    "Those predictions could be answering whether a piece of fruit in a photo is a banana or an apple, \n",
    "spotting people crossing the road in front of a self-driving car, whether the use of the word book in a sentence relates to a paperback or a hotel reservation,\n",
    "whether an email is spam, or recognizing speech accurately enough to generate captions for a YouTube video.\n",
    "\n",
    "The key difference from traditional computer software is that a human developer hasn't written code that instructs the system how to tell the difference between the banana and the apple.\n",
    "\n",
    "Instead a machine-learning model has been taught how to reliably discriminate between the fruits by being trained on a large amount of data, \n",
    "in this instance likely a huge number of images labelled as containing a banana or an apple.\n",
    "\n",
    "AI systems will generally demonstrate at least some of the following traits: planning, learning, reasoning, problem solving, \n",
    "knowledge representation, perception, motion, and manipulation and, to a lesser extent, social intelligence and creativity.\n",
    "Alongside machine learning, there are various other approaches used to build AI systems, including evolutionary computation,\n",
    "where algorithms undergo random mutations and combinations between generations in an attempt to \"evolve\" optimal solutions, and expert systems, \n",
    "where computers are programmed with rules that allow them to mimic the behavior of a human expert in a specific domain, for example an autopilot system flying a plane.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the texts\n",
    "\n",
    "import re \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "wordnet=WordNetLemmatizer()\n",
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "corpus = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    rewiew = re.sub('[^a-zA-Z]',' ',sentences[i])\n",
    "    rewiew = rewiew.lower()\n",
    "    rewiew = rewiew.split()\n",
    "    rewiew = [ps.stem(word) for word in rewiew if not word in \n",
    "    set(stopwords.words('english'))]\n",
    "    rewiew = ' '.join(rewiew)\n",
    "    corpus.append(rewiew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Bag of Words Model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 1500)\n",
    "X = cv.fit_transform(corpus).toarray()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50b26f52a78e56bb50a957cf14aee04c6c923725037f0b0901654ff3139df2fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
